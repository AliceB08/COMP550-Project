{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP550 - Final Project\n",
    "---\n",
    "\n",
    "Links:\n",
    "- https://www.kaggle.com/ficklemaverick/lyrics-generator\n",
    "- https://www.kaggle.com/danofer/music-lyrics-clean-export\n",
    "\n",
    "## Table of content\n",
    "[1. Imports](#imports)  \n",
    "[2. Import & Cleaning data and Exploratory Data Analysis](#imports-clean)  \n",
    "[3. Preprocessing steps](#preprocessing)  \n",
    "[4. Na√Øve majority model](#naive-model)   \n",
    "[5. Logistic Regression](#log-reg)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports  <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_GOOGLE_COLAB = False\n",
    "root_path = 'data/'\n",
    "if IN_GOOGLE_COLAB:\n",
    "    !pip install langdetect\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = 'drive/My Drive/COMP550-Project/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from langdetect import detect\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# nltk imports\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import & Cleaning data and Exploratory Data Analysis   <a class=\"anchor\" id=\"imports-clean\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Detecting the language of all the songs is very long (15 minutes). To avoid this step we import directly the preprocessed english that is split into 3 sets: training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CLEANED_DATA = True\n",
    "cleaned_data_path = root_path + \"cleaned_data.csv\"\n",
    "data_path = root_path + \"lyrics.csv\"\n",
    "data_raw = pd.read_csv(data_path)\n",
    "print(len(data_raw), \"songs in the dataset\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has the following columns:\n",
    "- **index** (int): index of the song in the dataset\n",
    "- **song** (string): name of the song\n",
    "- **year** (float) -> (int): release year\n",
    "- **artist** (string): artist of the song\n",
    "- **genre** (string): the genre, this is the label we want to predict\n",
    "- **lyrics** (string): the lyrics of the song. This is the data we will use to predict the genre. We need to preprocess this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remove the null elements, we are left with **265701** songs. We convert the year from float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_raw[pd.notnull(data_raw)]\n",
    "data_all = data_all.dropna(how='any',axis=0)\n",
    "data_all['year'] = pd.to_numeric(data_all['year'], downcast='integer')\n",
    "data_all['index'] = pd.to_numeric(data_all['index'], downcast='integer')\n",
    "data_all = data_all.reset_index(drop=True)\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only English songs, using the `langdetect` library. There are **237,363 English songs** in the previous 265,701 songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_CLEANED_DATA:\n",
    "    en_songs = []\n",
    "    for song in data_all['lyrics']:\n",
    "        try:\n",
    "            lang = detect(song)\n",
    "            if lang == 'en':\n",
    "                en_songs.append(True)\n",
    "            else:\n",
    "                en_songs.append(False)\n",
    "        except:\n",
    "            en_songs.append(False)\n",
    "    data_en = data_all[en_songs]\n",
    "    data_en.reset_index(drop=True)\n",
    "else:\n",
    "    data_en = pd.read_csv(cleaned_data_path)\n",
    "    \n",
    "data_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en['genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove songs where the labels are \"Other\" or \"Not Available\". This reduces the number of songs from 237363 to **215,825 songs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_en['genre'].tolist()\n",
    "keep_song = [genre not in ['Not Available', 'Other'] for genre in data_en['genre'].tolist()]\n",
    "data_en = data_en[keep_song]\n",
    "data_en = data_en.reset_index(drop=True)\n",
    "data_en['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the the number of songs in each genre category. **46,5% of the songs are Rock songs**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We split the data in training, validation and test sets\n",
    "The english songs are smplit into 3 sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_TO_INT = {'Pop':0, 'Hip-Hop':1, 'Rock':2, 'Metal':3, 'Country':4, 'Jazz':5, 'Electronic':6, 'Folk':7, 'R&B':8, 'Indie':9}\n",
    "lyrics = data_en['lyrics'].tolist()\n",
    "labels = np.array([GENRE_TO_INT[genre] for genre in data_en['genre'].tolist()])\n",
    "lyrics_train, lyrics_test, labels_train, labels_test = train_test_split(lyrics, labels, test_size=0.1, shuffle=True, random_state=43, stratify=labels)\n",
    "lyrics_train, lyrics_valid, labels_train, labels_valid = train_test_split(lyrics_train, labels_train, test_size=0.1, shuffle=True, random_state=43, stratify=labels_train)\n",
    "\n",
    "# Smaller dataset for wuick training\n",
    "# lyrics_selected and labels_selected contain the 25,000 songs that we consider in our project\n",
    "# lyrics_train and labels_train contain the 20,000 songs of the training set (80%)\n",
    "# lyrics_valid and labels_valid contain the 2,500 songs of the training set (10%)\n",
    "# lyrics_test and labels_test contain the 2,500 songs of the test set (10%)\n",
    "\n",
    "tmp_1, lyrics_selected, tmp_2, labels_selected = train_test_split(lyrics_train, labels_train, test_size=25000, shuffle=True, random_state=43, stratify=labels_train)\n",
    "lyrics_train, lyrics_selected_2, labels_train, labels_selected_2 = train_test_split(lyrics_selected, labels_selected, test_size=5000, shuffle=True, random_state=43, stratify=labels_selected)\n",
    "lyrics_valid, lyrics_test, labels_valid, labels_test = train_test_split(lyrics_selected_2, labels_selected_2, test_size=2500, shuffle=True, random_state=43, stratify=labels_selected_2)\n",
    "\n",
    "# print(\"Light training set length:\", len(lyrics_light))\n",
    "print(\"Training set length:\", len(lyrics_train))\n",
    "print(\"Validation set length:\", len(lyrics_valid))\n",
    "print(\"Test set length:\", len(lyrics_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing steps <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "The lyrics need to be cleaned before we can use them.\n",
    "- remove \\n line breaks\n",
    "- remove punctuation\n",
    "- lowercase the lyrics\n",
    "- remove verse and chorus indications that are under the form [verse x]\n",
    "- remove tokens that have a null length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace line breaks, removes punctuation, set everything to lowercase\n",
    "# removes word if length <= 2, [verse X] or [chorus y] indication\n",
    "# remove stopwords\n",
    "def my_preprocessor(song):\n",
    "    song = song.replace('\\n', ' ')\n",
    "    song = song.translate(str.maketrans('', '', string.punctuation))\n",
    "    song = song.lower()\n",
    "    song_token = song.split(' ')\n",
    "    song_token = [w for w in song_token if (len(w) >= 3 and w[0] != '[' and w[-1] != ']')]\n",
    "    song_token = [w for w in song_token if not any(c.isdigit() for c in w)]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    song_token = [w for w in song_token if (w not in stop_words and u'\\x9d' not in w)]\n",
    "    song = ' '.join(song_token)\n",
    "    return song\n",
    "\n",
    "# tokenize the song\n",
    "def my_tokenizer(song): \n",
    "    tokens = song.split(' ')\n",
    "    return tokens\n",
    "\n",
    "# tokenize the song and stems its tokens\n",
    "def my_tokenizer_stem(song): \n",
    "    tokens = song.split(' ') \n",
    "    stemmer = PorterStemmer() \n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "# tokenize the song and lemmas its tokens\n",
    "def my_tokenizer_lemma(song):\n",
    "    song_with_pos = pos_tag(song.split(' '))\n",
    "    POS_correspondance = {'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV, 'J': wordnet.ADJ}\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_song = [lemmatizer.lemmatize(w[0], POS_correspondance.get(w[1][0], wordnet.NOUN)) for w in song_with_pos]\n",
    "    return lemmatized_song\n",
    "\n",
    "print(my_tokenizer(my_preprocessor(lyrics_train[2]))[:10])\n",
    "print(my_tokenizer_stem(my_preprocessor(lyrics_train[2]))[:10])\n",
    "print(my_tokenizer_lemma(my_preprocessor(lyrics_train[2]))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create csvs for train, valid and test data\n",
    "In the rest of the jupyter notebook we directly import the preprocessed data.  \n",
    "There are 3 csvs:\n",
    "- `train_data.csv` containing 20,000 preprocessed english songs\n",
    "- `valid_data.csv` containing 2,500 preprocessed english songs\n",
    "- `test_data.csv` containing 2,500 preprocessed english songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics_train_preprocessed = [my_preprocessor(song) for song in lyrics_train]\n",
    "# lyrics_valid_preprocessed = [my_preprocessor(song) for song in lyrics_valid]\n",
    "# lyrics_test_preprocessed = [my_preprocessor(song) for song in lyrics_test]\n",
    "# train_df = pd.DataFrame.from_dict({\"lyrics\": lyrics_train_preprocessed, \"genre\": labels_train})\n",
    "# valid_df = pd.DataFrame.from_dict({\"lyrics\": lyrics_valid_preprocessed, \"genre\": labels_valid})\n",
    "# test_df = pd.DataFrame.from_dict({\"lyrics\": lyrics_test_preprocessed, \"genre\": labels_test})\n",
    "# train_df.to_csv(root_path+\"train_data.csv\", index=False)\n",
    "# valid_df.to_csv(root_path+\"valid_data.csv\", index=False)\n",
    "# test_df.to_csv(root_path+\"test_data.csv\", index=False)\n",
    "\n",
    "train_df = pd.read_csv(root_path + \"train_data.csv\")\n",
    "valid_df = pd.read_csv(root_path + \"valid_data.csv\")\n",
    "test_df = pd.read_csv(root_path + \"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Na√Øve Majority Model  <a class=\"anchor\" id=\"naive-model\"></a>\n",
    "In this na√Øve majority model, we guess that all the songs have the genre 'Rock', which is the genre that has the majority of songs. This is a first baseline model, that we can use to compare the results of logistic regression, naive bayes, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_df['genre'], [2]*len(train_df['lyrics']), target_names=list(GENRE_TO_INT.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision for our baseline model is **47%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Logistic Regression  <a class=\"anchor\" id=\"log-reg\"></a>\n",
    "We test different forms of the vectorised data: stemmed, lemmatized and no token transformation. The step to vectorize the data is quite long so we decide to test different hyperparameters of a model AFTER the vectorization is performed.\n",
    "\n",
    "Solver: liblinear. Although it doesn't support multinomial, it's the quickest solver (by far) and is the only one that converges after 1000 iterations.\n",
    "\n",
    "#### Best model\n",
    "Best accuracy with the following model : **58,6%** no stemming or lemmatization, TD-IDF vectorization, regularization strength C: 0.1, max_df: 0.7, max_features: 150000, ngram_range: bigram}.\n",
    "On development set: **59,52%**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "With a small dataset (10,000 songs) we grid search on the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lyrics = train_df['lyrics']\n",
    "train_labels = train_df['genre']\n",
    "lyrics_preprocessed = train_lyrics\n",
    "lyrics_stemmed = [' '.join(my_tokenizer_stem(song)) for song in train_lyrics]\n",
    "lyrics_lemmad = [' '.join(my_tokenizer_lemma(song)) for song in train_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i/10 for i in range(18, 30, 3)]\n",
    "# [i*1000 for i in range(150, 250, 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "GRID_SEARCH_ON = False\n",
    "pipeline = Pipeline([\n",
    "    # ('vect', CountVectorizer()),\n",
    "    ('vect', TfidfVectorizer()),    \n",
    "    ('clf', LogisticRegression(multi_class='auto', solver='lbfgs', penalty='l2', max_iter=100)),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': [0.8],\n",
    "    'vect__max_features': [210000],\n",
    "    'vect__ngram_range': [(1,2)],\n",
    "    'vect__norm': ['l2'],\n",
    "    'clf__C': [2.5, 2.6, 2.7, 2.8, 2.9],\n",
    "}\n",
    "\n",
    "# find the best parameters for both the feature extraction and the classifier\n",
    "if GRID_SEARCH_ON:\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    start = time.time()\n",
    "    grid_search.fit(lyrics_lemmad, train_labels)\n",
    "    end = time.time()\n",
    "    print(\"done in %0.3fs\" % (end - start))\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results grid search \n",
    "The different hyperparameters and ranges why are testing:\n",
    "- **tokenizer**: [my_tokenizer, my_tokenizer_stem, my_tokenizer_lemma].\n",
    "- **max_df**: range(0.3, 1)\n",
    "- **max_features**: range(10000, 200000)\n",
    "- **ngram_range**: unigrams, bigrams. Bigram models tend to have the best results.\n",
    "- **C**: range(0.01, 3). The regularization strength is the most important parameter to finetune. A value around 0.1 increases the accuracy up to 10% compared to a bad choice of strength. When TF-IDF is on, the strength needs to be around 2.\n",
    "- **TFIDF**: on or off (depends on which vectorizer we use). When turned on, the accuracy is higher.\n",
    "- **norm**: when TFIDF=on defines the unit norm of each row.\n",
    "\n",
    "There are a lot of different possible combinations. Here is the methodology for grid search.\n",
    "0. preprocessing = none\n",
    "1. Try out 3 different values for each hyperparameter (min, max, middle) and see which parameters modify the most the accuracy. For example the tokenizer doesn't change the accuracy that much, but the regularization strength affects a lot the accuracy.\n",
    "2. For each hyperparameter that doesn't have a big impacy, chose the value that gives the highest accuracy. If there is no trend (for example the hyperparameter sometimes give better results with a certain value and other times a worst result, take the value that has the smallest computation time).\n",
    "3. The value of regularization strength is the most important hyperparameter to determine. A value around 0.1 is a good choice.\n",
    "4. Little by little, trim the ranges of the hyperparameter choices, taking each time the one that affects the most the accuracy.\n",
    "5. Repeat from 0 for preprocessing = stemming, lemmatization\n",
    "6. Repeat from 0 for TFIDF = on\n",
    "\n",
    "**TFIDF=off**  \n",
    "Best with no tokenization modification: **55,7%** {C: 0,07, max_df: 0,7, max_features: 100000, ngram_range: bigram}  \n",
    "Best with stemming: **55,9%** {C: 0.1, max_df: 0.7, max_features: 150000, ngram_range: bigram}  \n",
    "Best with lemmatization: **55,5%** {C: 0.14, max_df: 0.7, max_features: 150000, ngram_range: bigram}\n",
    "\n",
    "**TFIDF=on**  \n",
    "Best with no tokenization modification:  **58,6%** {C: 2.6, max_df: 0.5, max_features: 210000, ngram_range: bigram, norm='l2'}  \n",
    "Best with stemming: **58,2%** {C: 2.2, max_df: 0.5, max_features: 25000, ngram_range: bigram, norm='l2'}  \n",
    "Best with lemmatization:  **58,5** {C: 2.8, max_df: 0.8, max_features: 210000, ngram_range: bigram, norm='l2'}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_df = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "grid_search_df.to_csv(root_path+\"result_reglog_tfidf_preprocessed_6.csv\", sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We compute the accuracy of the best model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.8, max_features=210000, ngram_range=(1, 2), norm='l2')\n",
    "classifier = LogisticRegression(multi_class='auto', solver='lbfgs', penalty='l2', C=2.8, max_iter=1000)\n",
    "lyrics_train_vec = vectorizer.fit_transform(train_df['lyrics'])\n",
    "lyrics_valid_vec = vectorizer.transform(valid_df['lyrics'])\n",
    "classifier.fit(lyrics_train_vec, train_df['genre'])\n",
    "accuracy_score(valid_df['genre'], classifier.predict(lyrics_valid_vec))"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
