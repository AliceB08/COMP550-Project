{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP550 - Final Project\n",
    "---\n",
    "\n",
    "Links:\n",
    "- https://www.kaggle.com/ficklemaverick/lyrics-generator\n",
    "- https://www.kaggle.com/danofer/music-lyrics-clean-export\n",
    "\n",
    "## Table of content\n",
    "[1. Imports](#imports)  \n",
    "[2. Import & Cleaning data and Exploratory Data Analysis](#imports-clean)  \n",
    "[3. Preprocessing steps](#preprocessing)  \n",
    "[4. Naïve majority model](#naive-model)   \n",
    "[5. Logistic Regression](#log-reg)  \n",
    "[6. Naïve Bayes](#naive-bayes)  \n",
    "[7. Support Vector Machine](#SVM)  \n",
    "[8. Sequencial model - LSTM](#LSTM)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports  <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_GOOGLE_COLAB = False\n",
    "root_path = 'data/'\n",
    "if IN_GOOGLE_COLAB:\n",
    "    !pip install langdetect\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_path = 'drive/My Drive/COMP550-Project/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from langdetect import detect\n",
    "from scipy.stats import uniform\n",
    "import warnings\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "# nltk imports\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# gensim imports\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import & Cleaning data and Exploratory Data Analysis   <a class=\"anchor\" id=\"imports-clean\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Detecting the language of all the songs is very long (15 minutes). To avoid this step we import directly the preprocessed english that is split into 3 sets: training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CLEANED_DATA = True\n",
    "cleaned_data_path = root_path + \"cleaned_data.csv\"\n",
    "data_path = root_path + \"lyrics.csv\"\n",
    "data_raw = pd.read_csv(data_path)\n",
    "print(len(data_raw), \"songs in the dataset\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has the following columns:\n",
    "- **index** (int): index of the song in the dataset\n",
    "- **song** (string): name of the song\n",
    "- **year** (float) -> (int): release year\n",
    "- **artist** (string): artist of the song\n",
    "- **genre** (string): the genre, this is the label we want to predict\n",
    "- **lyrics** (string): the lyrics of the song. This is the data we will use to predict the genre. We need to preprocess this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remove the null elements, we are left with **265701** songs. We convert the year from float to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = data_raw[pd.notnull(data_raw)]\n",
    "data_all = data_all.dropna(how='any',axis=0)\n",
    "data_all['year'] = pd.to_numeric(data_all['year'], downcast='integer')\n",
    "data_all['index'] = pd.to_numeric(data_all['index'], downcast='integer')\n",
    "data_all = data_all.reset_index(drop=True)\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only English songs, using the `langdetect` library. There are **237,363 English songs** in the previous 265,701 songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_CLEANED_DATA:\n",
    "    en_songs = []\n",
    "    for song in data_all['lyrics']:\n",
    "        try:\n",
    "            lang = detect(song)\n",
    "            if lang == 'en':\n",
    "                en_songs.append(True)\n",
    "            else:\n",
    "                en_songs.append(False)\n",
    "        except:\n",
    "            en_songs.append(False)\n",
    "    data_en = data_all[en_songs]\n",
    "    data_en.reset_index(drop=True)\n",
    "else:\n",
    "    data_en = pd.read_csv(cleaned_data_path)\n",
    "    \n",
    "data_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en['genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove songs where the labels are \"Other\" or \"Not Available\". This reduces the number of songs from 237363 to **215,825 songs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_en['genre'].tolist()\n",
    "keep_song = [genre not in ['Not Available', 'Other'] for genre in data_en['genre'].tolist()]\n",
    "data_en = data_en[keep_song]\n",
    "data_en = data_en.reset_index(drop=True)\n",
    "data_en['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the the number of songs in each genre category. **46,5% of the songs are Rock songs**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We split the data in training, validation and test sets\n",
    "The english songs are smplit into 3 sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_TO_INT = {'Pop':0, 'Hip-Hop':1, 'Rock':2, 'Metal':3, 'Country':4, 'Jazz':5, 'Electronic':6, 'Folk':7, 'R&B':8, 'Indie':9}\n",
    "INT_TO_GENRE = {0:'Pop', 1:'Hip-Hop', 2:'Rock', 3:'Metal', 4:'Country', 5:'Jazz', 6:'Electronic', 7:'Folk', 8:'R&B', 9:'Indie'}\n",
    "lyrics = data_en['lyrics'].tolist()\n",
    "labels = np.array([GENRE_TO_INT[genre] for genre in data_en['genre'].tolist()])\n",
    "lyrics_train, lyrics_test, labels_train, labels_test = train_test_split(lyrics, labels, test_size=0.1, shuffle=True, random_state=43, stratify=labels)\n",
    "lyrics_train, lyrics_valid, labels_train, labels_valid = train_test_split(lyrics_train, labels_train, test_size=0.1, shuffle=True, random_state=43, stratify=labels_train)\n",
    "\n",
    "# Smaller dataset for wuick training\n",
    "# lyrics_selected and labels_selected contain the 25,000 songs that we consider in our project\n",
    "# lyrics_train and labels_train contain the 20,000 songs of the training set (80%)\n",
    "# lyrics_valid and labels_valid contain the 2,500 songs of the training set (10%)\n",
    "# lyrics_test and labels_test contain the 2,500 songs of the test set (10%)\n",
    "\n",
    "tmp_1, lyrics_selected, tmp_2, labels_selected = train_test_split(lyrics_train, labels_train, test_size=25000, shuffle=True, random_state=43, stratify=labels_train)\n",
    "lyrics_train, lyrics_selected_2, labels_train, labels_selected_2 = train_test_split(lyrics_selected, labels_selected, test_size=5000, shuffle=True, random_state=43, stratify=labels_selected)\n",
    "lyrics_valid, lyrics_test, labels_valid, labels_test = train_test_split(lyrics_selected_2, labels_selected_2, test_size=2500, shuffle=True, random_state=43, stratify=labels_selected_2)\n",
    "\n",
    "# print(\"Light training set length:\", len(lyrics_light))\n",
    "print(\"Training set length:\", len(lyrics_train))\n",
    "print(\"Validation set length:\", len(lyrics_valid))\n",
    "print(\"Test set length:\", len(lyrics_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing steps <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "The lyrics need to be cleaned before we can use them.\n",
    "- remove \\n line breaks\n",
    "- remove punctuation\n",
    "- lowercase the lyrics\n",
    "- remove verse and chorus indications that are under the form [verse x]\n",
    "- remove tokens that have a null length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace line breaks, removes punctuation, set everything to lowercase\n",
    "# removes word if length <= 2, [verse X] or [chorus y] indication\n",
    "# remove stopwords\n",
    "def my_preprocessor(song):\n",
    "    song = song.replace('\\n', ' ')\n",
    "    song = song.translate(str.maketrans('', '', string.punctuation))\n",
    "    song = song.lower()\n",
    "    song_token = song.split(' ')\n",
    "    song_token = [w for w in song_token if (len(w) >= 3 and w[0] != '[' and w[-1] != ']')]\n",
    "    song_token = [w for w in song_token if not any(c.isdigit() for c in w)]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    song_token = [w for w in song_token if (w not in stop_words and u'\\x9d' not in w)]\n",
    "    song = ' '.join(song_token)\n",
    "    return song\n",
    "\n",
    "# tokenize the song\n",
    "def my_tokenizer(song): \n",
    "    tokens = song.split(' ')\n",
    "    return tokens\n",
    "\n",
    "# tokenize the song and stems its tokens\n",
    "def my_tokenizer_stem(song): \n",
    "    tokens = song.split(' ') \n",
    "    stemmer = PorterStemmer() \n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "# tokenize the song and lemmas its tokens\n",
    "def my_tokenizer_lemma(song):\n",
    "    song_with_pos = pos_tag(song.split(' '))\n",
    "    POS_correspondance = {'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV, 'J': wordnet.ADJ}\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_song = [lemmatizer.lemmatize(w[0], POS_correspondance.get(w[1][0], wordnet.NOUN)) for w in song_with_pos]\n",
    "    return lemmatized_song\n",
    "\n",
    "print(my_tokenizer(my_preprocessor(lyrics_train[2]))[:10])\n",
    "print(my_tokenizer_stem(my_preprocessor(lyrics_train[2]))[:10])\n",
    "print(my_tokenizer_lemma(my_preprocessor(lyrics_train[2]))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create csvs for train, valid and test data\n",
    "In the rest of the jupyter notebook we directly import the preprocessed data.  \n",
    "There are 3 csvs:\n",
    "- `train_data.csv` containing 20,000 preprocessed english songs\n",
    "- `valid_data.csv` containing 2,500 preprocessed english songs\n",
    "- `test_data.csv` containing 2,500 preprocessed english songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuples_to_preprocess = [\n",
    "#     (lyrics_train, labels_train, \"train_data_2.csv\"),\n",
    "#     (lyrics_valid, labels_valid, \"valid_data_2.csv\"),\n",
    "#     (lyrics_test, labels_test, \"test_data_2.csv\"),      \n",
    "# ]\n",
    "# for lyrics, labels, csv_name in tuples_to_preprocess:\n",
    "#     lyrics_preprocessed = [my_preprocessor(song) for song in lyrics]\n",
    "#     lyrics_stemmed = [' '.join(my_tokenizer_stem(song)) for song in lyrics_preprocessed]\n",
    "#     lyrics_lemmad = [' '.join(my_tokenizer_lemma(song)) for song in lyrics_preprocessed]\n",
    "#     tmp_df = pd.DataFrame.from_dict({\n",
    "#         \"lyrics\": lyrics_preprocessed, \"lyrics_stemmed\": lyrics_stemmed, \"lyrics_lemmad\": lyrics_lemmad, \"genre\": labels\n",
    "#     })\n",
    "#     tmp_df.to_csv(root_path+csv_name, index=False)\n",
    "\n",
    "# data_en_all_preprocessed = [my_preprocessor(song) for song in data_en['lyrics']]\n",
    "# data_en_all_df = pd.DataFrame.from_dict({\"lyrics\": data_en_all_preprocessed, \"genre\": np.array([GENRE_TO_INT[genre] for genre in data_en['genre'].tolist()])})\n",
    "# data_en_all_df.to_csv(root_path+\"data_en_all_data.csv\", index=False)\n",
    "\n",
    "train_df = pd.read_csv(root_path + \"train_data.csv\")\n",
    "valid_df = pd.read_csv(root_path + \"valid_data.csv\")\n",
    "test_df = pd.read_csv(root_path + \"test_data.csv\")\n",
    "data_en_all_df = pd.read_csv(root_path + \"data_en_all_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Naïve Majority Model  <a class=\"anchor\" id=\"naive-model\"></a>\n",
    "In this naïve majority model, we guess that all the songs have the genre 'Rock', which is the genre that has the majority of songs. This is a first baseline model, that we can use to compare the results of logistic regression, naive bayes, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_df['genre'], [2]*len(train_df['lyrics']), target_names=list(GENRE_TO_INT.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision for our baseline model is **47%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Logistic Regression  <a class=\"anchor\" id=\"log-reg\"></a>\n",
    "We test different forms of the vectorised data: stemmed, lemmatized and no token transformation. The step to vectorize the data is quite long so we decide to test different hyperparameters of a model AFTER the vectorization is performed.\n",
    "\n",
    "##### With no hyperparameter tuning:\n",
    "Accuracy on training set: 0.9474%  \n",
    "Accuracy on validation set: 0.5452%  \n",
    "\n",
    "#### Best model with k-fold cross validation\n",
    "Best accuracy with the following model : **58,6%** no stemming or lemmatization, TD-IDF vectorization, regularization strength C: 0.1, max_df: 0.7, max_features: 150000, ngram_range: bigram}.\n",
    "On development set: **59,52%**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "With a small dataset (10,000 songs) we grid search on the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lyrics = train_df['lyrics']\n",
    "lyrics_stemmed = train_df['lyrics_stemmed']\n",
    "lyrics_lemmad = train_df['lyrics_lemmad']\n",
    "train_labels = train_df['genre']\n",
    "lyrics_preprocessed = train_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "GRID_SEARCH_ON = False\n",
    "pipeline = Pipeline([\n",
    "    # ('vect', CountVectorizer()),\n",
    "    ('vect', TfidfVectorizer()),    \n",
    "    ('clf', LogisticRegression(multi_class='auto', solver='lbfgs', penalty='l2', max_iter=100)),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': [0.8],\n",
    "    'vect__max_features': [210000],\n",
    "    'vect__ngram_range': [(1,2)],\n",
    "    'vect__norm': ['l2'],\n",
    "    'clf__C': [2.5, 2.6, 2.7, 2.8, 2.9],\n",
    "}\n",
    "\n",
    "# find the best parameters for both the feature extraction and the classifier\n",
    "if GRID_SEARCH_ON:\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    start = time.time()\n",
    "    grid_search.fit(lyrics_lemmad, train_labels)\n",
    "    end = time.time()\n",
    "    print(\"done in %0.3fs\" % (end - start))\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results grid search \n",
    "The different hyperparameters and ranges why are testing:\n",
    "- **tokenizer**: [my_tokenizer, my_tokenizer_stem, my_tokenizer_lemma].\n",
    "- **max_df**: range(0.3, 1)\n",
    "- **max_features**: range(10000, 200000)\n",
    "- **ngram_range**: unigrams, bigrams. Unigram and bigram models tend to have the best results.\n",
    "- **C**: range(0.01, 3). The regularization strength is the most important parameter to finetune. A value around 0.1 increases the accuracy up to 10% compared to a bad choice of strength. When TF-IDF is on, the strength needs to be around 2.\n",
    "- **TFIDF**: on or off (depends on which vectorizer we use). When turned on, the accuracy is higher.\n",
    "- **norm**: when TFIDF=on defines the unit norm of each row.\n",
    "\n",
    "There are a lot of different possible combinations. Here is the methodology for grid search.\n",
    "0. preprocessing = none\n",
    "1. Try out 3 different values for each hyperparameter (min, max, middle) and see which parameters modify the most the accuracy. For example the tokenizer doesn't change the accuracy that much, but the regularization strength affects a lot the accuracy.\n",
    "2. For each hyperparameter that doesn't have a big impacy, chose the value that gives the highest accuracy. If there is no trend (for example the hyperparameter sometimes give better results with a certain value and other times a worst result, take the value that has the smallest computation time).\n",
    "3. The value of regularization strength is the most important hyperparameter to determine. A value around 0.1 is a good choice.\n",
    "4. Little by little, trim the ranges of the hyperparameter choices, taking each time the one that affects the most the accuracy.\n",
    "5. Repeat from 0 for preprocessing = stemming, lemmatization\n",
    "6. Repeat from 0 for TFIDF = on\n",
    "\n",
    "**TFIDF=off**  \n",
    "Best with no tokenization modification: **55,7%** {C: 0,07, max_df: 0,7, max_features: 100000, ngram_range: bigram}  \n",
    "Best with stemming: **55,9%** {C: 0.1, max_df: 0.7, max_features: 150000, ngram_range: bigram}  \n",
    "Best with lemmatization: **55,5%** {C: 0.14, max_df: 0.7, max_features: 150000, ngram_range: bigram}\n",
    "\n",
    "**TFIDF=on**  \n",
    "Best with no tokenization modification:  **58,6%** {C: 2.6, max_df: 0.5, max_features: 210000, ngram_range: bigram, norm='l2'}  \n",
    "Best with stemming: **58,2%** {C: 2.2, max_df: 0.5, max_features: 25000, ngram_range: bigram, norm='l2'}  \n",
    "Best with lemmatization:  **58,5** {C: 2.8, max_df: 0.8, max_features: 210000, ngram_range: bigram, norm='l2'}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search_df = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "# grid_search_df.to_csv(root_path+\"result_reglog_tfidf_preprocessed_6.csv\", sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We compute the accuracy of the best model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(max_df=0.8, max_features=210000, ngram_range=(1, 2), norm='l2')\n",
    "# classifier = LogisticRegression(multi_class='auto', solver='lbfgs', penalty='l2', C=2.8, max_iter=1000)\n",
    "# lyrics_train_vec = vectorizer.fit_transform(train_df['lyrics'])\n",
    "# lyrics_valid_vec = vectorizer.transform(valid_df['lyrics'])\n",
    "# classifier.fit(lyrics_train_vec, train_df['genre'])\n",
    "# print(\"Accuracy on training set:\", accuracy_score(train_df['genre'], classifier.predict(lyrics_train_vec)))\n",
    "# print(\"Accuracy on validation set:\", accuracy_score(valid_df['genre'], classifier.predict(lyrics_valid_vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Naïve Bayes Model  <a class=\"anchor\" id=\"naive-bayes\"></a>\n",
    "We test different forms of the vectorised data: stemmed, lemmatized and no token transformation. The step to vectorize the data is quite long so we decide to test different hyperparameters of a model AFTER the vectorization is performed.\n",
    "\n",
    "#### With no hyperparameter tuning:\n",
    "Accuracy on training set: 0.6843%  \n",
    "Accuracy on validation set: 0.5856%  \n",
    "\n",
    "#### Best model with k-fold cross validation\n",
    "Best accuracy with TFIDF and stemming on training set: **63,91%**  \n",
    "On validation set: **59,76%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "GRID_SEARCH_ON = False\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    #('vect', TfidfVectorizer()),    \n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'vect__max_df': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'vect__max_features': [100000,150000,200000],\n",
    "    'vect__ngram_range': [(1,1),(1,2)],\n",
    "    #'vect__norm': ['l2'], #not a parameter for CountVectorizer()\n",
    "    'clf__fit_prior': [True],\n",
    "    'clf__alpha': [1],\n",
    "}\n",
    "\n",
    "# find the best parameters for both the feature extraction and the classifier\n",
    "if GRID_SEARCH_ON:\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    start = time.time()\n",
    "    grid_search.fit(lyrics_lemmad, train_labels)\n",
    "    end = time.time()\n",
    "    print(\"done in %0.3fs\" % (end - start))\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results grid search \n",
    "The different hyperparameters and ranges why are testing:\n",
    "- **tokenizer**: [my_tokenizer, my_tokenizer_stem, my_tokenizer_lemma]. \n",
    "- **max_df**: range(0.3, 1). This value is pretty much 0.2 across the board for all the following experiments.\n",
    "- **max_features**: range(10000, 200000). For TFIDF = off, this value is in the upper end of the range. For TFIDF = on, this value is typically much lower (see results)\n",
    "- **ngram_range**: unigrams, unigrams and bigrams, bigrams. (1,2) is the best performing parameter in the following tests.\n",
    "- **alpha**: float - controls smoothing; 0 is no smoothing, 1 is Laplace smoothing. \n",
    "- **fit_prior**: bool - whether to learn class priors. All test run best with TRUE.\n",
    "- **TFIDF**: on or off (depends on which vectorizer we use).\n",
    "- **norm**: when TFIDF=on defines the unit norm of each row.\n",
    "\n",
    "There are a lot of different possible combinations. Here is the methodology for grid search.\n",
    "0. preprocessing = none\n",
    "1. Try out 3 different values for each hyperparameter (min, max, middle) and see which parameters modify the most the accuracy. For example the tokenizer doesn't change the accuracy that much, but the regularization strength affects a lot the accuracy.\n",
    "2. For each hyperparameter that doesn't have a big impacy, chose the value that gives the highest accuracy. If there is no trend (for example the hyperparameter sometimes give better results with a certain value and other times a worst result, take the value that has the smallest computation time).\n",
    "3. The value of regularization strength is the most important hyperparameter to determine. A value around 0.1 is a good choice.\n",
    "4. Little by little, trim the ranges of the hyperparameter choices, taking each time the one that affects the most the accuracy.\n",
    "5. Repeat from 0 for preprocessing = stemming, lemmatization\n",
    "6. Repeat from 0 for TFIDF = on\n",
    "\n",
    "Initial parameters run as: parameters = { \n",
    "    'vect__max_df': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'vect__max_features': [10000,100000,200000],\n",
    "    'vect__ngram_range': [(1,1),(1,2),(2,2)],\n",
    "    'vect__norm': ['l2','l1'], #not a parameter for CountVectorizer()\n",
    "    'clf__fit_prior': [True,False],\n",
    "    'clf__alpha': [0,0.5,1],\n",
    "From here we refine our selection criteria per tokenized set.\n",
    "\n",
    "**TFIDF=off**\n",
    "\n",
    "Best with no tokenization modification: **57.12%** {'clf__alpha': 1, 'clf__fit_prior': True, 'vect__max_df': 0.2, 'vect__max_features': 150000, 'vect__ngram_range': (1, 2)}\n",
    "\n",
    "Best with stemming: **56.76%**  {clf__alpha: 1,\tclf__fit_prior: True, vect__max_df: 0.2, vect__max_features: 200000, vect__ngram_range: (1, 2)}\n",
    "\n",
    "Best with lemmatization: **56.92%** {'clf__alpha': 1, 'clf__fit_prior': True, 'vect__max_df': 0.3, 'vect__max_features': 150000, 'vect__ngram_range': (1, 2)}\n",
    "\n",
    "**TFIDF=on**\n",
    "\n",
    "Best with no tokenization modification: **58.20%** {'clf__alpha': 0.1, 'clf__fit_prior': True, 'vect__max_df': 0.2, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2), 'vect__norm': 'l2'}\n",
    "\n",
    "Best with stemming: **58.36%** {'clf__alpha': 0.1, 'clf__fit_prior': True, 'vect__max_df': 0.2, 'vect__max_features': 7500, 'vect__ngram_range': (1, 2), 'vect__norm': 'l2'}\n",
    "\n",
    "Best with lemmatization: **58.25%** {'clf__alpha': 0.1, 'clf__fit_prior': True, 'vect__max_df': 0.2, 'vect__max_features': 7500, 'vect__ngram_range': (1, 2), 'vect__norm': 'l2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search_df = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "# grid_search_df.to_csv(root_path+\"result_tuned_lemmad.csv\", sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We compute the accuracy of the best model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(max_df=0.2, max_features=7500, ngram_range=(1, 2), norm='l2')#add best parameters\n",
    "# classifier = MultinomialNB(alpha=0.1,fit_prior=True)#add best parameters\n",
    "# train_lyrics_stemmed = [' '.join(my_tokenizer_stem(song)) for song in train_df['lyrics']]\n",
    "# valid_lyrics_stemmed = [' '.join(my_tokenizer_stem(song)) for song in valid_df['lyrics']]\n",
    "# lyrics_train_vec = vectorizer.fit_transform(train_lyrics_stemmed)\n",
    "# lyrics_valid_vec = vectorizer.transform(valid_lyrics_stemmed)\n",
    "# classifier.fit(lyrics_train_vec, train_df['genre'])\n",
    "# print(\"Accuracy on training set:\", accuracy_score(train_df['genre'], classifier.predict(lyrics_train_vec)))\n",
    "# print(\"Accuracy on validation set:\", accuracy_score(valid_df['genre'], classifier.predict(lyrics_valid_vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Support Vector Machine  <a class=\"anchor\" id=\"SVM\"></a>\n",
    "We test different forms of the vectorised data: stemmed, lemmatized and no token transformation. The step to vectorize the data is quite long so we decide to test different hyperparameters of a model AFTER the vectorization is performed.\n",
    "\n",
    "SVMs are 2 class classifiers. With the LinearSVC there is multiclass support according to a one-vs-the-rest scheme. We also try out other kernels such as XXX\n",
    "\n",
    "#### With no hypterparameter tuning:\n",
    "Accuracy on training set: 0.9945%  \n",
    "Accuracy on validation set: 0.4756%  \n",
    "\n",
    "#### Best model with k-fold cross validation\n",
    "Best accuracy: with TFIDF and lemmatization, for linear kernel.  \n",
    "Accuracy on training set: **93,17%**  \n",
    "Accuracy on validation set: **59,56%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i/10 for i in range(1, 10)]\n",
    "# [i*1000 for i in range(150, 250, 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "GRID_SEARCH_ON = False\n",
    "pipeline = Pipeline([\n",
    "    # ('vect', CountVectorizer()),\n",
    "    ('vect', TfidfVectorizer()),    \n",
    "    # ('clf', LinearSVC()),\n",
    "    ('clf', SVC()),    \n",
    "])\n",
    "\n",
    "parameters = { \n",
    "    'vect__max_df': [0.5, 1],\n",
    "    # 'vect__max_features': [600000, 700000, 800000,],\n",
    "    'vect__ngram_range': [(1,2)],\n",
    "    'clf__C': [0.01, 0.1, 1, 2, 3],\n",
    "    'clf__kernel': ['poly'], # 'rbf', 'sigmoid'\n",
    "    'clf__gamma': ['scale', 'auto']    \n",
    "}\n",
    "\n",
    "# find the best parameters for both the feature extraction and the classifier\n",
    "if GRID_SEARCH_ON:\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=2, n_jobs=-1, verbose=1)\n",
    "    start = time.time()\n",
    "    grid_search.fit(lyrics_stemmed, train_labels)\n",
    "    end = time.time()\n",
    "    print(\"done in %0.3fs\" % (end - start))\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search_df = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "# grid_search_df.to_csv(root_path+\"result_SVC_tfidf_stemmed_1.csv\", sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results grid search \n",
    "The different hyperparameters and ranges why are testing:\n",
    "- **tokenizer**: [my_tokenizer, my_tokenizer_stem, my_tokenizer_lemma]. \n",
    "- **max_df**: [0.2, 0.5, 0.8]\n",
    "- **max_features**: [10000, 50000, 100000, 150000, 200000, 250000]\n",
    "- **ngram_range**: unigrams, unigrams and bigrams.\n",
    "- **C**: [0.5, 1, 2].\n",
    "- **TFIDF**: on or off (depends on which vectorizer we use).\n",
    "- **norm**: when TFIDF=on defines the unit norm of each row.\n",
    "\n",
    "Initial parameters run as: parameters = { \n",
    "    'vect__max_df': [0.2, 0.5, 0.8],\n",
    "    'vect__max_features': [10000, 50000, 100000, 200000],\n",
    "    'vect__ngram_range': [(1, 1), (1,2)],\n",
    "    'clf__C': [0.5, 1, 2],\n",
    "From here we refine our selection criteria per tokenized set.\n",
    "\n",
    "**TFIDF=off**  \n",
    "Best with no tokenization modification: **58,56%** {max_df=1, ngram: bigram, C=0.0006}  \n",
    "Best with stemming: **57,4%** {max_df=0.5, max_features=100000, ngram: bigram, C=0.001}  \n",
    "Best with lemmatization: **57,3%** {max_df=0.5, ngram: bigram, C=0.0009}  \n",
    "\n",
    "**TFIDF=on**\n",
    "Best with no tokenization modification: **58,2%** {max_df=0.4, ngram: bigram, C=0.3}  \n",
    "Best with stemming: **58,4%** {max_df=0.3, ngram: bigram, C=0.4}  \n",
    "Best with lemmatization: **58,5%** {max_df=0.6, ngram: bigram, C=0.305}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# # vectorizer = TfidfVectorizer(max_df=0.6, ngram_range=(1, 2), norm='l2')#add best parameters\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 2))#add best parameters\n",
    "# # classifier = LinearSVC(C=0.305) #add best parameters\n",
    "# classifier = SVC() #add best parameters\n",
    "# # train_lyrics_lemmad = [' '.join(my_tokenizer_lemma(song)) for song in train_df['lyrics']]\n",
    "# train_lyrics_lemmad = train_df['lyrics']\n",
    "# valid_lyrics_lemmad = valid_df['lyrics']\n",
    "# # valid_lyrics_lemmad = [' '.join(my_tokenizer_lemma(song)) for song in valid_df['lyrics']]\n",
    "# lyrics_train_vec = vectorizer.fit_transform(train_lyrics_lemmad)\n",
    "# lyrics_valid_vec = vectorizer.transform(valid_lyrics_lemmad)\n",
    "# classifier.fit(lyrics_train_vec, train_df['genre'])\n",
    "# print(\"Accuracy on training set:\", accuracy_score(train_df['genre'], classifier.predict(lyrics_train_vec)))\n",
    "# print(\"Accuracy on validation set:\", accuracy_score(valid_df['genre'], classifier.predict(lyrics_valid_vec)))\n",
    "# print(\"Done in {:03.2f} seconds\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Sequenciel model - LSTM  <a class=\"anchor\" id=\"LSTM\"></a>\n",
    "\n",
    "## TODO:\n",
    "- change var names, functions, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 20000 # in paper 395,722 not 20,000\n",
    "VALID_SIZE = 2500 # in paper 2500 not 49,776\n",
    "\n",
    "VOCAB_SIZE = 30000 # and 1 for unknown, and 1 for mask\n",
    "WORD_VEC_SIZE = 100\n",
    "MAX_WORDS = 200 # max number of words in song\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Word embedding\n",
    "\n",
    "We create word embeddings with Word2Vec, from the gensim package. There are two possible models: continuous bag of words and Skip Gram. The models are trained on the whole data (the 215,824 preprocessed english songs). To avoid re-computing the models, they are saved in the files `model_CBOW_215824_en_songs.model` and `model_Skip_Gram_215824_en_songs.model`.\n",
    "Helpful resources : \n",
    "- https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\n",
    "- https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/\n",
    "- https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial#Training-the-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_SAVED_W2V_MODELS = True\n",
    "if LOAD_SAVED_W2V_MODELS:\n",
    "    model_CBOW = Word2Vec.load(root_path+'model_CBOW_215824_en_songs.model')\n",
    "    model_Skip_Gram = Word2Vec.load(root_path+'model_Skip_Gram_215824_en_songs.model')    \n",
    "else:\n",
    "    lyrics_en_all = data_en_all_df['lyrics']\n",
    "    data = [song.split() for song in lyrics_en_all]\n",
    "\n",
    "    # Create CBOW model with gensim https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\n",
    "    # Parameters: min_count=Ignores all words with total frequency lower than this.\n",
    "    start_CBOW=time.time()  \n",
    "    model_CBOW = gensim.models.Word2Vec(data, min_count=5, size=WORD_VEC_SIZE, window=5, sg=0, workers=cores-1)\n",
    "    end_CBOW=time.time()\n",
    "    print(\"CBOW done in\", end_CBOW-start_CBOW)\n",
    "    # Create Skip Gram model\n",
    "    start_SG=time.time()\n",
    "    model_Skip_Gram = gensim.models.Word2Vec(data, min_count=5, size=WORD_VEC_SIZE, window=10, sg=1, workers=cores-1)\n",
    "    end_SG=time.time()\n",
    "    print(\"Skip Gram done in:\", end_SG-start_SG)\n",
    "\n",
    "    # Save models for later\n",
    "    # model_CBOW.save(root_path+'model_CBOW_215824_en_songs.model')\n",
    "    # model_Skip_Gram.save(root_path+'model_Skip_Gram_215824_en_songs.model')\n",
    "    \n",
    "    \n",
    "print(\"Cosine similarity between 'love' and 'girl' - CBOW : \", model_CBOW.wv.similarity('love', 'girl'))\n",
    "print(\"Cosine similarity between 'love' and 'pasta' - CBOW : \", model_CBOW.wv.similarity('love', 'pasta')) \n",
    "print(\"Cosine similarity between 'love' and 'girl' - Skip Gram : \", model_Skip_Gram.wv.similarity('love', 'girl'))\n",
    "print(\"Cosine similarity between 'love' and 'pasta' - Skip Gram : \", model_Skip_Gram.wv.similarity('love', 'pasta'))\n",
    "print(\"{}: {:.4f}\".format(*model_CBOW.wv.most_similar(positive=['woman', 'queen'], negative=['woman'])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping most common words\n",
    "We want to keep the vocab_size most common words (for example **30,000** like in the paper). There are **66,401** embedded words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2c = {}\n",
    "for item in model_CBOW.wv.vocab:\n",
    "    w2c[item]=model_CBOW.wv.vocab[item].count\n",
    "w2cSorted=dict(sorted(w2c.items(), key=lambda x: x[1],reverse=True))\n",
    "w2cSortedList = list(w2cSorted.keys())\n",
    "MOST_FREQUENT_WORDS = w2cSortedList[:VOCAB_SIZE]\n",
    "print(MOST_FREQUENT_WORDS[:10])\n",
    "\n",
    "WORD_TO_INT = {word:i+1 for i,word in enumerate(MOST_FREQUENT_WORDS)}\n",
    "INT_TO_WORD = {i+1:word for i,word in enumerate(MOST_FREQUENT_WORDS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform each song so that each word becomes the index of that word in the list `MOST_FREQUENT_WORDS`. The index n°**30001** corresponds to the *UNK* words and the index n°**0** corresponds to the pad (used later on so that all songs are 600 words long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_EMBEDDING_IDXS = True\n",
    "\n",
    "def get_embedded_song_idx(song):\n",
    "    embedded_song = np.array([], dtype = int)\n",
    "    for word in song:\n",
    "        idx=WORD_TO_INT.get(word, VOCAB_SIZE+1)\n",
    "        embedded_song = np.append(embedded_song, idx)\n",
    "    return embedded_song\n",
    "\n",
    "def embed_songs_idx(songs):\n",
    "    return np.array([get_embedded_song_idx(song) for song in songs])\n",
    "\n",
    "if LOAD_EMBEDDING_IDXS:\n",
    "    embed_song_idxs_train = np.load(root_path + 'CBOW_embedded_train_idxs.npy', allow_pickle=True)\n",
    "    embed_song_idxs_valid = np.load(root_path + 'CBOW_embedded_valid_idxs.npy', allow_pickle=True)\n",
    "else:\n",
    "    embed_song_idxs_train=embed_songs_idx([song.split() for song in train_df['lyrics']])\n",
    "#     np.save(root_path + 'CBOW_embedded_train_idxs', embed_song_idxs_train)\n",
    "    embed_songs_indexes_valid=embed_songs_idx([song.split() for song in valid_df['lyrics']])\n",
    "#     np.save(root_path + 'CBOW_embedded_valid_idxs', embed_songs_indexes_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad data for songs to be same length\n",
    "Som songs are short and longer than other. We cut the long songs and pad the shorter ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_len = [len(x) for x in embed_song_idxs_train]\n",
    "pd.Series(reviews_len).hist()\n",
    "plt.show()\n",
    "pd.Series(reviews_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_line(song):\n",
    "    '''Pads/truncates a song line to have length MAX_WORDS'''\n",
    "    size = min(MAX_WORDS, len(song))\n",
    "    to_add = MAX_WORDS-size\n",
    "    # new_line = np.concatenate((np.zeros(to_add,), song[:size]))\n",
    "    new_line = np.concatenate((song[:size], np.zeros(to_add,)))\n",
    "    return new_line\n",
    "\n",
    "# Get train data\n",
    "train_data = np.zeros((TRAIN_SIZE, MAX_WORDS), dtype = int)\n",
    "train_labels = train_df['genre'].to_numpy()\n",
    "for i, song in enumerate(embed_song_idxs_train):\n",
    "    arr = pad_line(song)\n",
    "    train_data[i,:] = arr\n",
    "\n",
    "# Get dev data\n",
    "valid_labels = valid_df['genre'].to_numpy()\n",
    "valid_data = np.zeros((VALID_SIZE, MAX_WORDS), dtype = int)\n",
    "for i, song in enumerate(embed_song_idxs_valid):\n",
    "    arr = pad_line(song)\n",
    "    valid_data[i,:] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model - WIP\n",
    "\n",
    "Useful ressources:\n",
    "- https://towardsdatascience.com/sentiment-analysis-using-lstm-step-by-step-50d074f09948\n",
    "- https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "- https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79\n",
    "- model.eval(): https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615\n",
    "\n",
    "Other:\n",
    "- https://mlwhiz.com/blog/2018/12/17/text_classification/\n",
    "- https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79\n",
    "- https://towardsdatascience.com/sentiment-analysis-using-lstm-step-by-step-50d074f09948\n",
    "- https://github.com/samarth-agrawal-86/sentiment-analysis-pytorch/blob/master/sentiment_model_class.py\n",
    "- https://github.com/lukysummer/Movie-Review-Sentiment-Analysis-LSTM-Pytorch\n",
    "- https://github.com/lukysummer/Movie-Review-Sentiment-Analysis-LSTM-Pytorch/blob/master/sentiment_analysis_LSTM.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_SIZE = 20000\n",
    "# VALID_SIZE = 2500\n",
    "# VOCAB_SIZE = 30000 # and 1 for unknown, and 1 for mask\n",
    "# WORD_VEC_SIZE = 100\n",
    "# MAX_WORDS = 200 # max number of words in song\n",
    "\n",
    "\n",
    "## parameter setting\n",
    "N_EPOCHS = 200\n",
    "BATCH_SIZE = 200\n",
    "N_HIDDEN = 32\n",
    "N_GENRES = 10\n",
    "LR = 0.001\n",
    "WORD_EMBEDDING = np.concatenate(([np.zeros(100, dtype=np.float32)], model_CBOW.wv[w2cSortedList[:VOCAB_SIZE+1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongsDataset(data.Dataset):\n",
    "    def __init__(self, dataset, labels):\n",
    "        self.dataset = dataset\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = torch.tensor(self.dataset[index], dtype=torch.long)\n",
    "        X = X.to(device)\n",
    "        y = torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        y = y.to(device)        \n",
    "        return X, y\n",
    "\n",
    "train_dataset = SongsDataset(train_data, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataset = SongsDataset(valid_data, valid_labels)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, n_hidden, n_layers, n_directions, output_size, batch_size, word_embeddings, drop_p=0.5):\n",
    "        super(GenreLSTM, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.batch_size = batch_size\n",
    "        self.n_directions = n_directions\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(n_vocab, n_embed)\n",
    "        # self.word_embeddings.weight.data.copy_(torch.from_numpy(word_embeddings))\n",
    "        self.word_embeddings.weight = nn.Parameter(torch.from_numpy(word_embeddings), requires_grad=False)\n",
    "        self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, dropout=drop_p, batch_first=True, bidirectional=n_directions==2)\n",
    "        self.dropout = nn.Dropout(drop_p)\n",
    "        self.fc = nn.Linear(n_directions*n_hidden, output_size)\n",
    "        # self.hidden = self.init_hidden()\n",
    "        \n",
    "    # def init_hidden(self):\n",
    "    #     h0 = Variable(torch.zeros(self.n_layers*self.n_directions, self.batch_size, self.n_hidden).cuda())\n",
    "    #     c0 = Variable(torch.zeros(self.n_layers*self.n_directions, self.batch_size, self.n_hidden).cuda())\n",
    "    #     return (h0, c0)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        batch_size = sentence.size(0)\n",
    "        # (batch_size, seq_length)\n",
    "        out = self.word_embeddings(sentence)\n",
    "        # (batch_size, seq_length, n_embed)\n",
    "        # out, self.hidden = self.lstm(out, self.hidden)\n",
    "        out, _ = self.lstm(out)\n",
    "        # (batch_size, seq_length, n_directions*n_hidden)\n",
    "        out = self.dropout(out)\n",
    "        # (batch_size, seq_length, n_directions*n_hidden)\n",
    "        out = self.fc(out[:, -1])\n",
    "        # (batch_size, n_output)\n",
    "        # out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenreLSTM(VOCAB_SIZE+2, WORD_VEC_SIZE, N_HIDDEN, 1, 1, N_GENRES, BATCH_SIZE, WORD_EMBEDDING)\n",
    "model = model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "train_loss_ = []\n",
    "test_loss_ = []\n",
    "train_acc_ = []\n",
    "test_acc_ = []\n",
    "### training proc\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(epoch, time.time() - start)\n",
    "                    \n",
    "    # Training\n",
    "    total_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    total = 0.0\n",
    "    for local_batch, local_labels in train_loader:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "        # Model computations\n",
    "        model.zero_grad()\n",
    "        model.batch_size = len(local_labels)\n",
    "        # model.hidden = model.init_hidden()\n",
    "\n",
    "        genre_scores = model(local_batch)\n",
    "        loss = loss_function(genre_scores, local_labels)    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calc training acc\n",
    "        _, predicted = torch.max(genre_scores.data, 1)\n",
    "        # print(\"train\", predicted)\n",
    "        total_acc += (predicted == local_labels).sum()\n",
    "        total += len(local_labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    train_loss_.append(total_loss / total)\n",
    "    train_acc_.append(total_acc / total)\n",
    "    \n",
    "    # Validation\n",
    "    total_acc = 0.0\n",
    "    total_loss = 0.0\n",
    "    total = 0.0\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for local_batch, local_labels in valid_loader:\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "            genre_scores = model(local_batch)\n",
    "            loss = loss_function(genre_scores, local_labels)\n",
    "            \n",
    "            # calc testing acc\n",
    "            _, predicted = torch.max(genre_scores.data, 1)\n",
    "            # print(\"valid\", predicted)\n",
    "            total_acc += (predicted == local_labels).sum()\n",
    "            total += len(local_labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        test_loss_.append(total_loss / total)\n",
    "        test_acc_.append(total_acc / total)\n",
    "        print('[Epoch: %3d/%3d] Training Loss: %.6f, Testing Loss: %.6f, Training Acc: %.3f, Testing Acc: %.3f'\n",
    "              % (epoch, N_EPOCHS, train_loss_[epoch], test_loss_[epoch], train_acc_[epoch], test_acc_[epoch]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_len = [len(x) for x in embed_song_idxs_train]\n",
    "pd.Series(reviews_len).hist()\n",
    "plt.show()\n",
    "pd.Series(reviews_len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(train_data))\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size + 2, embed_size, weights=[embedding_matrix], input_length=MAX_WORDS, trainable=True))\n",
    "model.add(LSTM(n_hidden, activation='sigmoid', return_sequences=True))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(num_genres, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=learning_rate)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print \"model fitting - Baseline LSTM\"\n",
    "print model.summary()\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpointer = ModelCheckpoint(filepath='results/lstm/lstmbest.hdf5',verbose=1,save_best_only=True)\n",
    "hist = model.fit(train_data, train_labels, validation_data=(dev_data, dev_labels),\n",
    "          nb_epoch=training_epochs, batch_size=batch_size, callbacks=[checkpointer, earlystopping])\n",
    "print hist.history\n",
    "model.save('results/lstm/lstm.h5')\n",
    "\n",
    "evals = model.evaluate(test_data, test_labels)\n",
    "print \"Test accuracy:\", evals\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
